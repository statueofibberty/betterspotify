<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Results</title>

    <!-- Bootstrap core CSS -->
    <link href="https://fonts.googleapis.com/css?family=Montserrat|Raleway" rel="stylesheet">
    <link href="vendor/bootstrap/css/bootstrap.css" rel="stylesheet">
    <link href="vendor/bootstrap/css/styles.css" rel="stylesheet">


</head>

<body>

<!-- Navigation -->
<nav class="navbar navbar-expand-lg navbar-dark bg-dark static-top">
    <div class="container">
        <a class="navbar-brand" href="#">BetterSpotify_</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
            <ul class="navbar-nav ml-auto">
                <li class="nav-item">
                    <a class="nav-link" href="index.html">Home
                    </a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="intro.html">Introduction and EDA</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="review.html">Literature Review and Related Work</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="model.html">Models</a>
                </li>
                <li class="nav-item active">
                    <a class="nav-link" href="results.html">Results and Conclusion</a>
                    <span class="sr-only">(current)</span>
                </li>
            </ul>
        </div>
    </div>
</nav>

<!-- Page Content -->
<div class="container">
    <div class="row">
        <div class="col-lg-12 text-left">
            <h2 class="mt-5">Our Results and Conclusions</h2>

            <h6 class="mt-5">Table of Contents</h6>
            
            <ul id="markdown-toc">
                <li><a href="#1-results" id="markdown-toc-1-results">1. Results</a>    <ul>
                    <li><a href="#1-testing-framework" id="markdown-toc-1-testing-framework">1) Testing Framework</a></li>
                    <li><a href="#2-model-variations" id="markdown-toc-2-model-variations">2) Model Variations</a></li>
                    <li><a href="#3-example-results" id="markdown-toc-3-example-results">3) Example Results</a></li>
<!--                     <li><a href="#4-feature-selection" id="markdown-toc-4-feature-selection">4) Feature Selection</a></li> -->
<!--                     <li><a href="#5-standardization" id="markdown-toc-5-standardization">5) Standardization</a></li> -->
<!--                     <li><a href="#6-playlist-selection" id="markdown-toc-6-playlist-selection">6) Playlist Selection</a></li> -->
                </ul>
                </li>
                <li><a href="#2-conclusions" id="markdown-toc-2-conclusions">2. Conclusions and Future Work</a>    <ul>
                    <li><a href="#1-conclusions" id="markdown-toc-1-conclusions">1) Conclusions</a></li>
                    <li><a href="#2-future-work" id="markdown-toc-2-future-work">2) Future Work</a></li>
                </ul>
                </li>
            </ul>





        </div>
    </div>

    <!-- First Section -->

    <h4 class="mt-5" id = 1-results >Results</h4>

    <div class="row">
        <div class="col-lg-12 text-left" id = "1-testing-framework">

            <h6 class="mt-5">1. Testing Framework</h6>
            
            <p> <b> Song Validation Method: </b> For a given playlist, we randomly sampled a subset of songs (usually about 80%) from
                that playlist and used these as input "training data" for our model. The remaining songs (usually about 20%) were used 
                as "testing data." We then ran our model (both pooling and ranking) on the training data and returned as output our 
                highest ranked songs (usually the same number of songs as in the testing data). Our metric for success in this case 
                was the number of songs in the testing data that appeared in our output. </p>
                
            <p> With this validation method, we often found that few songs from the testing data appeared in our model's output. 
                We find this to be quite reasonable, since there are many songs that could properly extend a given subset of a playlist.
                Further, with so many available songs to choose from, it would be remarkable if any model could consistently predict
                the songs in the testing set, especially when one considers that the playlists we have were assembled by the arbitrary
                tastes of Spotify users, and there is no objective measure of what properly constitutes a cohesive playlist. </p>
                
            <p> <b> Artist Validation Method: </b> We sought a second method of validation, to see if we could improve performance. The 
                procedure we used was identical to that of the <b> Song Validation Method</b>, except we redefine the metric of success
                to be the number of artists that appeared in the testing data that also appeared in out output. </p>
            
            <p> We saw similar results with this testing framework, for the same reasons as listed above. </p>    

        </div>
    </div>
    
    <!-- Second Section -->

    <div class="row">
        <div class="col-lg-12 text-left" id = "2-model-variations">

            <h6 class="mt-5">2. Feature Selection and Model Variations </h6>
            
            <p> We took several approached to feature selection. Within our testng framework, it is difficult
                to discriminate between different methods of feature selection, however we have found several approaches we find to be 
                valid. Of our features, we determined several which should be dropped. These include the track's key, time signature, 
                duration, and position in playlist. Intuitively, these features wouldn't discriminate well the types of songs we'd like 
                to select (for example, two totally different songs can have the same duration, key, or time signature). </p>
            
            <p> Once we had our set of features, we took several approaches in their use. We examined models both with and without
                the "artist genre" feature. When included, we one-hot encoded artist genre. We decided to exclude artist genre in our 
                ranking model, since we had already used it in the pooling model, and the large list of artist genres made one-hot 
                encoding rather expensive to run. We also experimented with dropping out some of our remaining features to evaluate 
                their relative importance, and we also tried weighting some features more heavily than others when evaluating cosine 
                similarity. 
            </p>


        </div>
    </div>
    
    <!-- Third Section -->
    <div class="row">
        <div class="col-lg-12 text-left" id = "3-example-results">

            <h6 class="mt-5">3. Example Results</h6>

        </div>
    </div>
    
    <!-- First Section -->

    <h4 class="mt-5" id = 2-conclusions >Conclusions and Future Work</h4>

    <div class="row">
        <div class="col-lg-12 text-left" id = "1-conclusions">

            <h6 class="mt-5">1. Conclusions</h6>

            <p> The goal of this project was to create a playlist extension tool for Spotify users. The tool was designed to take a user's
                playlist as input, and provide a series of suggested songs similar to the songs in their playlist. Ultimately, while our
                model successfully predicts a series of songs for the user, we don't have a well-established framework in which to 
                evaluate its successes and shortcomings. We find that our methods are accurate, and that given the proper testing
                framework we would be able to improve its predictive power. </p>
            
        </div>
    </div>
    
    <!-- Second Section -->

    <div class="row">
        <div class="col-lg-12 text-left" id = "2-future-work">

            <h6 class="mt-5">2. Future Work</h6>
            
            <p> To expand and improve our current model, we could examine the effects of interaction terms on our current features. We 
                could also try and find a better proxy for track genre than our current use of artist genre. Spotify stores a genre for 
                each album (not individual songs). Perhaps using album genre, or both album and artist genre, would be a better surrogate
                for track genre. </p>
            
            <p> We could also try and use a completely different framework. One of the challenges of this project was the lack of an
                appropriate response variable, which prevented us from using many of the modelling techniques that we used in CS109a. 
                It would be interesting to pursue different unsupervised learning techniques (for example, k means clustering)
                to see if we could improve our predictions. 

        </div>
    </div>
   



    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

</body>

</html>
